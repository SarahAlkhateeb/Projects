{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming assignment 2A: Political stance classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Implementing your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "import pandas as pd\n",
    "\n",
    "# clean the data\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# baseline classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "# several classification algorithms\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# for converting training and test datasets into matrices\n",
    "# TfidfVectorizer does this specifically for documents\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# for splitting the dataset into training and test sets\n",
    "# and for selecting model hyperparameters\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# for evaluating the quality of the classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1</td>\n",
       "      <td>... people who have NEVER voted... sneaky way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/0</td>\n",
       "      <td>Being a member of the European Union is a bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0/0</td>\n",
       "      <td>Brexit is bad. Immigrants make Britain great. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0/0</td>\n",
       "      <td>Britain is basically Pompeii if the Pompeii ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1</td>\n",
       "      <td>Britain's exit is a huge blow to the dream of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Annotation                                            Comment\n",
       "0        1/1  ... people who have NEVER voted... sneaky way ...\n",
       "1        0/0  Being a member of the European Union is a bit ...\n",
       "2        0/0  Brexit is bad. Immigrants make Britain great. ...\n",
       "3        0/0  Britain is basically Pompeii if the Pompeii ha...\n",
       "4        1/1  Britain's exit is a huge blow to the dream of ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the training data (final set 13,520 instances))\n",
    "df_f = pd.read_csv('a2a_train_final.tsv', sep = '\\t', header=None, names=['Annotation', 'Comment'])\n",
    "df_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13517 entries, 0 to 13516\n",
      "Data columns (total 2 columns):\n",
      "Annotation    13517 non-null object\n",
      "Comment       13517 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 211.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_f.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two solutions for choosing the annotation to use. Both of them choose the annotation if there is only one and both chooses the one that is not -1 in case of tie.\n",
    "\n",
    "The first one is below. If there is disagreement between the annotations, this one picks the first annotation. This is a good solution assuming that there are some characteristics that are hard to recognize for the people but maybe easier for the computer. The first annotator had the context of the text so we can trust his/her choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = df_f[\"Annotation\"]\n",
    "# more strict version\n",
    "newScore1 = []\n",
    "toRemove1 = []\n",
    "# less strict version\n",
    "newScore2 = []\n",
    "index = 0\n",
    "clearScores = 0\n",
    "for annot in score:\n",
    "    \n",
    "    votes = annot.split(\"/\")\n",
    "    majority = Counter()\n",
    "    \n",
    "    # Counter object to count the occurences of different annotations\n",
    "    for vote in votes:\n",
    "        majority[vote] += 1\n",
    "        \n",
    "    # if there is a clear winner, go with it\n",
    "    if len(majority)==1:\n",
    "        newScore1.append(majority.most_common()[0][0])\n",
    "        newScore2.append(majority.most_common()[0][0])\n",
    "        clearScores += 1\n",
    "    else:\n",
    "        # if there if one score with more counts than any other\n",
    "        if majority.most_common()[0][1] > majority.most_common()[1][1]:\n",
    "            # and that count is not -1 we get it as newScore\n",
    "            if int(majority.most_common()[0][0])!=-1:\n",
    "                newScore1.append(majority.most_common()[0][0])\n",
    "                newScore2.append(majority.most_common()[0][0])\n",
    "            else:\n",
    "                # if it is -1 we either remove the row\n",
    "                toRemove1.append(index)\n",
    "                # or keep the clear score\n",
    "                newScore2.append(majority.most_common()[1][0])\n",
    "        # if there are two scores with same counts and one of them is -1\n",
    "        # we keep the clear call\n",
    "        elif len(majority)==2: \n",
    "            if int(majority.most_common()[1][0])==-1:\n",
    "                newScore1.append(majority.most_common()[0][0])  \n",
    "                newScore2.append(majority.most_common()[0][0])  \n",
    "            elif int(majority.most_common()[0][0])==-1:\n",
    "                newScore1.append(majority.most_common()[1][0])  \n",
    "                newScore2.append(majority.most_common()[1][0])\n",
    "            else:\n",
    "                # if no -1, but disagreement we remove\n",
    "                toRemove1.append(index)\n",
    "                # if there is a tie between 0 and 1 we keep the original\n",
    "                newScore2.append(votes[0])\n",
    "        else:\n",
    "            # in any other case we remove the row from the strict version\n",
    "            toRemove1.append(index)\n",
    "            # but in the less strict version we keep some more:\n",
    "            # if there is a tie between 0 and 1 we keep the original\n",
    "            newScore2.append(votes[0])\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11005 clear scores out of 13517\n",
      "In the more strict case we remove 1107\n",
      "In the less strict case we remove 0\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \" + str(clearScores) + \" clear scores out of \" + str(len(df_f['Annotation']))) \n",
    "print(\"In the more strict case we remove \" + str(len(toRemove1)))\n",
    "print(\"In the less strict case we remove \" + '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_strict = df_f[\"Comment\"].drop(toRemove1)\n",
    "\n",
    "Y_strict = newScore1\n",
    "\n",
    "X_train_s, X_eval_s, Y_train_s, Y_eval_s = train_test_split(X_strict, Y_strict,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U1')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_strict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Highest scoring words in pro-Brexit: \n",
      "\n",
      "[('the', 9534), ('to', 5316), ('and', 4187), ('of', 3802), ('a', 3581), ('is', 2860), ('in', 2330), ('I', 2019), ('for', 1905), ('EU', 1898), ('that', 1783), ('be', 1556), ('will', 1533), ('we', 1412), ('have', 1307), ('are', 1267), ('it', 1239), ('The', 1211), ('they', 1062), ('with', 1035)]\n",
      "\n",
      "**Highest scoring words in anti-Brexit: \n",
      "\n",
      "[('the', 9235), ('to', 5310), ('and', 4177), ('of', 3641), ('a', 3539), ('is', 2745), ('in', 2387), ('I', 1999), ('EU', 1826), ('for', 1801), ('that', 1734), ('will', 1648), ('be', 1608), ('we', 1395), ('The', 1302), ('have', 1298), ('it', 1278), ('are', 1256), ('Brexit', 1182), ('UK', 1037)]\n"
     ]
    }
   ],
   "source": [
    "# Count all words appear in 'pro-Brexit (1)' and 'anti-Brexit (0)' labels\n",
    "w_count = {}\n",
    "w_pro = []\n",
    "w_anti = []\n",
    "freqs_pro = Counter()\n",
    "freqs_anti = Counter()\n",
    "\n",
    "for i in range(len(Y_strict)):  \n",
    "    if Y_strict[i] == '1':\n",
    "        w_pro.append(words[i])\n",
    "    else:\n",
    "        w_anti.append(words[i])\n",
    "w_count['w_pro'] = sum([len(p) for p in w_pro])\n",
    "w_count['w_anti'] = sum([len(n) for n in w_anti])\n",
    "\n",
    "# Count how many times each word appears in 'pro-Brexit (1)' or 'anti-Brexit (0)' documents\n",
    "\n",
    "for doc in w_pro:\n",
    "    for p in doc:\n",
    "        freqs_pro[p] += 1\n",
    "for doc in w_anti:\n",
    "      for n in doc:\n",
    "            freqs_anti[n] += 1\n",
    "\n",
    "#print(w_count)\n",
    "#print(freqs_pro)\n",
    "#print(freqs_anti)\n",
    "\n",
    "print(\"**Highest scoring words in pro-Brexit: \")\n",
    "print()\n",
    "print(freqs_pro.most_common(20))\n",
    "print()\n",
    "print(\"**Highest scoring words in anti-Brexit: \")\n",
    "print()\n",
    "print(freqs_anti.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lose = df_f[\"Comment\"]\n",
    "\n",
    "Y_lose = newScore2\n",
    "\n",
    "X_train_l, X_eval_l, Y_train_l, Y_eval_l = train_test_split(X_lose, Y_lose,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U1')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_lose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we apply TF-IDF vectorization on training and test comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv1 = TfidfVectorizer()\n",
    "X_train_trans_s = dv1.fit_transform(X_train_s)\n",
    "X_eval_trans_s = dv1.transform(X_eval_s)\n",
    "dv2 = TfidfVectorizer()\n",
    "X_train_trans_l = dv2.fit_transform(X_train_l)\n",
    "X_eval_trans_l = dv2.transform(X_eval_l)\n",
    "dv3 = TfidfVectorizer()\n",
    "X_s_trans = dv3.fit_transform(X_strict)\n",
    "dv4 = TfidfVectorizer()\n",
    "X_l_trans = dv4.fit_transform(X_lose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train different classifiers on the more and less strictly pre-processed training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we train the dummy classifier to have a baseline\n",
    "def train_dummy(X, Y, X_eval_trans):\n",
    "    clf = DummyClassifier()\n",
    "    clf.fit(X,Y)\n",
    "    training_score = clf.score(X, Y)\n",
    "    dummy_pred = clf.predict(X_eval_trans)\n",
    "    return training_score, dummy_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to select the best classifier by calculating training and prediction accuracy as well as using GridSearch cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NB(X, Y, X_eval_trans):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X,Y)\n",
    "    training_score = clf.score(X, Y)\n",
    "    nb_pred = clf.predict(X_eval_trans)\n",
    "    return training_score, nb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVC(X, Y, X_eval_trans):\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X,Y)\n",
    "    training_score = clf.score(X, Y)\n",
    "    svc_pred = clf.predict(X_eval_trans)\n",
    "    return training_score, svc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SGD(X, Y, X_eval_trans):\n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(X,Y)\n",
    "    training_score = clf.score(X, Y)\n",
    "    sgd_pred = clf.predict(X_eval_trans)\n",
    "    return training_score, sgd_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Gradient boosting\n",
    "def train_GB(X, Y, X_eval_trans):\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(X, Y)\n",
    "    training_score = clf.score(X, Y)\n",
    "    gb_pred = clf.predict(X_eval_trans)\n",
    "    return training_score, gb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Decision Tree\n",
    "def train_DT(X, Y, X_eval_trans):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X, Y)\n",
    "    training_score = clf.score(X, Y)\n",
    "    dt_pred = clf.predict(X_eval_trans)\n",
    "    return training_score, dt_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Logistic Regression\n",
    "def train_LR(X, Y, X_eval_trans):\n",
    "    clf = LogisticRegression(solver='lbfgs')\n",
    "    clf.fit(X, Y)\n",
    "    training_score = clf.score(X, Y)\n",
    "    lr_pred = clf.predict(X_eval_trans)\n",
    "    return training_score, lr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GSCV(X, Y, scores, tp_SVC, tp_NB, tp_SGD, tp_GB, tp_DT, tp_LR):    \n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print(\"Support vector classifier: \")\n",
    "        clf_SVC = GridSearchCV(SVC(), tp_SVC, scoring='%s_macro' % score)\n",
    "        param_scores(X, Y, clf_SVC)\n",
    "        print(\"Naive Bayes classifier: \")\n",
    "        clf_NB = GridSearchCV(MultinomialNB(), tp_NB, scoring='%s_macro' % score)\n",
    "        param_scores(X, Y, clf_NB)\n",
    "        print(\"Stochastic Gradient Descent classifier: \")\n",
    "        clf_SGD = GridSearchCV(SGDClassifier(), tp_SGD, scoring='%s_macro' % score)\n",
    "        param_scores(X, Y, clf_SGD)\n",
    "        print(\"Gradient Boosting classifier: \")\n",
    "        clf_GB = GridSearchCV(GradientBoostingClassifier(), tp_GB, scoring='%s_macro' % score)\n",
    "        param_scores(X, Y, clf_GB)\n",
    "        print(\"Decision Tree classifier: \")\n",
    "        clf_DT = GridSearchCV(DecisionTreeClassifier(), tp_DT, scoring='%s_macro' % score)\n",
    "        param_scores(X, Y, clf_DT)\n",
    "        print(\"Logisic Regression classifier: \")\n",
    "        clf_LR = GridSearchCV(LogisticRegression(), tp_LR, scoring='%s_macro' % score)\n",
    "        param_scores(X, Y, clf_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_scores(X, Y, clf):\n",
    "    clf.fit(X, Y)\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Grid scores on development set:\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_all(X_train_trans, Y_train, X_eval_trans, Y_eval):\n",
    "    print(\"Training scores: \")\n",
    "    \n",
    "    dummy_training_score, dummy_pred = train_dummy(X_train_trans,Y_train, X_eval_trans)\n",
    "    print(\"Dummy training score is \" + str(dummy_training_score))\n",
    "    NB_training_score, NB_pred = train_NB(X_train_trans,Y_train, X_eval_trans)\n",
    "    print(\"Naive Bayes training score is \" + str(NB_training_score))\n",
    "    SVC_training_score, SVC_pred =  train_SVC(X_train_trans,Y_train, X_eval_trans)\n",
    "    print(\"Support Vector Classifier training score is \" + str(SVC_training_score))\n",
    "    SGDC_training_score, SGDC_pred =  train_SGD(X_train_trans,Y_train, X_eval_trans)\n",
    "    print(\"Stochastic Gradient Descent training score is \" + str(SGDC_training_score))\n",
    "    GB_training_score, GB_pred =  train_GB(X_train_trans,Y_train, X_eval_trans)\n",
    "    print(\"Gradient Boosting training score is \" + str(GB_training_score))\n",
    "    DT_training_score, DT_pred =  train_DT(X_train_trans,Y_train, X_eval_trans)\n",
    "    print(\"Decision Tree training score is \" + str(DT_training_score))\n",
    "    LR_training_score, LR_pred =  train_LR(X_train_trans,Y_train, X_eval_trans)\n",
    "    print(\"Logistic Regression training score is \" + str(LR_training_score))\n",
    "    \n",
    "    print()\n",
    "    print(\"The highest training score is \" + \n",
    "          str(max(dummy_training_score, NB_training_score, SVC_training_score, \n",
    "             SGDC_training_score, GB_training_score, DT_training_score, LR_training_score)))\n",
    "    \n",
    "    print()\n",
    "    print(\"Accuracy scores: \")\n",
    "    \n",
    "    dummy_acc = accuracy_score(Y_eval, dummy_pred)\n",
    "    NB_acc = accuracy_score(Y_eval, NB_pred)\n",
    "    SVC_acc = accuracy_score(Y_eval, SVC_pred)\n",
    "    SGDC_acc = accuracy_score(Y_eval, SGDC_pred)\n",
    "    GB_acc = accuracy_score(Y_eval, GB_pred)\n",
    "    DT_acc = accuracy_score(Y_eval, DT_pred)\n",
    "    LR_acc = accuracy_score(Y_eval, LR_pred)\n",
    "\n",
    "\n",
    "    print('     |  true  |  false ')\n",
    "    print('----------------------')\n",
    "    print('dummy| {:.4f} | {:.4f}'.format(dummy_acc, (1-dummy_acc)))\n",
    "    print('  NB | {:.4f} | {:.4f}'.format(NB_acc, (1-NB_acc)))\n",
    "    print(' SVC | {:.4f} | {:.4f}'.format(SVC_acc, (1-SVC_acc)))\n",
    "    print('SGDC | {:.4f} | {:.4f}'.format(SGDC_acc, (1-SGDC_acc)))\n",
    "    print(' GB  | {:.4f} | {:.4f}'.format(GB_acc, (1-GB_acc)))\n",
    "    print(' DT  | {:.4f} | {:.4f}'.format(DT_acc, (1-DT_acc)))\n",
    "    print(' LR  | {:.4f} | {:.4f}'.format(LR_acc, (1-LR_acc)))\n",
    "\n",
    "    print()\n",
    "    print(\"The highest prediction score is \" + \n",
    "          str(max(dummy_acc, NB_acc, SVC_acc, SGDC_acc, GB_acc, DT_acc, LR_acc)))\n",
    "    \n",
    "    print()\n",
    "    print(\"Examples: \")\n",
    "    \n",
    "    #print(X_eval[0:10])\n",
    "    print(\"The truth is: \")\n",
    "    print('Y  : ' + ' '.join(Y_eval[0:10]))\n",
    "    print(\"Predictions are: \")\n",
    "    print('dum: ' + ' '.join(dummy_pred[0:10]))\n",
    "    print('NB : ' + ' '.join(NB_pred[0:10]))\n",
    "    print('SVC: '+ ' '.join(SVC_pred[0:10]))\n",
    "    print('SGD: '+ ' '.join(SGDC_pred[0:10]))\n",
    "    print('GB : '+' '.join(GB_pred[0:10]))\n",
    "    print('DT : '+' '.join(DT_pred[0:10]))\n",
    "    print('LR : '+' '.join(LR_pred[0:10]))\n",
    "    \n",
    "    print()\n",
    "    print(\"Confusion matrices: \")\n",
    "    \n",
    "    print(\"Naive Bayes: \")\n",
    "    print(confusion_matrix(Y_eval, NB_pred))\n",
    "    print(\"Support Vector: \")\n",
    "    print(confusion_matrix(Y_eval, SVC_pred))\n",
    "    print(\"Stochastic Gradient Descent: \")\n",
    "    print(confusion_matrix(Y_eval, SGDC_pred))\n",
    "    print(\"Gradient Boosting: \")\n",
    "    print(confusion_matrix(Y_eval, GB_pred))\n",
    "    print(\"Decision Tree: \")\n",
    "    print(confusion_matrix(Y_eval, DT_pred))\n",
    "    print(\"Logistic Regression: \")\n",
    "    print(confusion_matrix(Y_eval, LR_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRICT\n",
      "\n",
      "Training scores: \n",
      "Dummy training score is 0.4992949234488316\n",
      "Naive Bayes training score is 0.8845688960515713\n",
      "Support Vector Classifier training score is 0.9510475423045931\n",
      "Stochastic Gradient Descent training score is 0.8972602739726028\n",
      "Gradient Boosting training score is 0.7601732473811442\n",
      "Decision Tree training score is 0.9998992747784046\n",
      "Logistic Regression training score is 0.8583803384367445\n",
      "\n",
      "The highest training score is 0.9998992747784046\n",
      "\n",
      "Accuracy scores: \n",
      "     |  true  |  false \n",
      "----------------------\n",
      "dummy| 0.5060 | 0.4940\n",
      "  NB | 0.7877 | 0.2123\n",
      " SVC | 0.7764 | 0.2236\n",
      "SGDC | 0.7824 | 0.2176\n",
      " GB  | 0.7139 | 0.2861\n",
      " DT  | 0.6495 | 0.3505\n",
      " LR  | 0.7776 | 0.2224\n",
      "\n",
      "The highest prediction score is 0.7876712328767124\n",
      "\n",
      "Examples: \n",
      "4271     I do not want to be part of federal Europe. We...\n",
      "5775     In our opinion, Britain can find a lot of reso...\n",
      "2654     Dont be fooled by Leavers saying Remain have i...\n",
      "10590    This is the moment for us to change - to fight...\n",
      "7458           Nope, not changed my mind. Brexit please...\n",
      "924      BREXIT is a madness. It was just an empty poli...\n",
      "8868     Thank you Boris Johnson and your government. O...\n",
      "3787     Harder times for the EU having to survive on 8...\n",
      "9578     The UK's going to get raked over the proverbia...\n",
      "1164     Brexit 2016 was a chaotic vote, held at the he...\n",
      "Name: Comment, dtype: object\n",
      "The truth is: \n",
      "Y  : 1 1 0 0 0 1 0 1 1 1\n",
      "Predictions are: \n",
      "dum: 1 0 1 0 0 1 1 1 1 0\n",
      "NB : 1 0 0 0 0 1 0 1 1 1\n",
      "SVC: 1 0 1 0 0 1 0 1 1 1\n",
      "SGD: 1 0 1 0 1 1 0 1 1 1\n",
      "GB : 1 1 1 1 0 0 0 1 0 1\n",
      "DT : 1 0 0 0 0 1 0 1 1 1\n",
      "LR : 1 0 1 0 1 1 0 1 1 1\n",
      "\n",
      "Confusion matrices: \n",
      "Naive Bayes: \n",
      "[[ 875  334]\n",
      " [ 193 1080]]\n",
      "Support Vector: \n",
      "[[ 920  289]\n",
      " [ 266 1007]]\n",
      "Stochastic Gradient Descent: \n",
      "[[ 924  285]\n",
      " [ 255 1018]]\n",
      "Gradient Boosting: \n",
      "[[859 350]\n",
      " [360 913]]\n",
      "Decision Tree: \n",
      "[[758 451]\n",
      " [419 854]]\n",
      "Logistic Regression: \n",
      "[[944 265]\n",
      " [287 986]]\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "lOOSE\n",
      "Training scores: \n",
      "Dummy training score is 0.4985665402755942\n",
      "Naive Bayes training score is 0.8750578007953389\n",
      "Support Vector Classifier training score is 0.938592435031906\n",
      "Stochastic Gradient Descent training score is 0.8815314898733007\n",
      "Gradient Boosting training score is 0.7401276241561084\n",
      "Decision Tree training score is 0.9986127809118653\n",
      "Logistic Regression training score is 0.8469434939424767\n",
      "\n",
      "The highest training score is 0.9986127809118653\n",
      "\n",
      "Accuracy scores: \n",
      "     |  true  |  false \n",
      "----------------------\n",
      "dummy| 0.5078 | 0.4922\n",
      "  NB | 0.7511 | 0.2489\n",
      " SVC | 0.7426 | 0.2574\n",
      "SGDC | 0.7530 | 0.2470\n",
      " GB  | 0.7075 | 0.2925\n",
      " DT  | 0.6394 | 0.3606\n",
      " LR  | 0.7585 | 0.2415\n",
      "\n",
      "The highest prediction score is 0.7585059171597633\n",
      "\n",
      "Examples: \n",
      "4271     I do not want to be part of federal Europe. We...\n",
      "5775     In our opinion, Britain can find a lot of reso...\n",
      "2654     Dont be fooled by Leavers saying Remain have i...\n",
      "10590    This is the moment for us to change - to fight...\n",
      "7458           Nope, not changed my mind. Brexit please...\n",
      "924      BREXIT is a madness. It was just an empty poli...\n",
      "8868     Thank you Boris Johnson and your government. O...\n",
      "3787     Harder times for the EU having to survive on 8...\n",
      "9578     The UK's going to get raked over the proverbia...\n",
      "1164     Brexit 2016 was a chaotic vote, held at the he...\n",
      "Name: Comment, dtype: object\n",
      "The truth is: \n",
      "Y  : 1 1 1 0 0 1 1 0 0 0\n",
      "Predictions are: \n",
      "dum: 1 0 1 0 0 1 1 0 1 0\n",
      "NB : 1 0 1 0 0 1 1 0 0 1\n",
      "SVC: 1 1 1 0 0 1 1 0 0 1\n",
      "SGD: 1 0 1 0 0 1 1 0 0 1\n",
      "GB : 1 0 0 0 0 1 1 0 0 1\n",
      "DT : 1 1 0 0 1 0 1 0 0 1\n",
      "LR : 1 0 1 0 0 1 1 0 0 1\n",
      "\n",
      "Confusion matrices: \n",
      "Naive Bayes: \n",
      "[[ 935  391]\n",
      " [ 282 1096]]\n",
      "Support Vector: \n",
      "[[ 965  361]\n",
      " [ 335 1043]]\n",
      "Stochastic Gradient Descent: \n",
      "[[ 976  350]\n",
      " [ 318 1060]]\n",
      "Gradient Boosting: \n",
      "[[941 385]\n",
      " [406 972]]\n",
      "Decision Tree: \n",
      "[[835 491]\n",
      " [484 894]]\n",
      "Logistic Regression: \n",
      "[[ 993  333]\n",
      " [ 320 1058]]\n"
     ]
    }
   ],
   "source": [
    "print(\"STRICT\")\n",
    "print()\n",
    "training_all(X_train_trans_s, Y_train_s, X_eval_trans_s, Y_eval_s)\n",
    "print()\n",
    "print('-----------------------------------------------')\n",
    "print()\n",
    "print(\"LOOSE\")\n",
    "training_all(X_train_trans_l, Y_train_l, X_eval_trans_l, Y_eval_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters_NB = [{'alpha': [0, 1, 100], 'fit_prior':[True, False]}]\n",
    "tuned_parameters_SVC = [{'kernel': ['rbf'], 'gamma': [0.1, 1, 10],\n",
    "                     'C': [0.5, 1, 5, 10]},\n",
    "                    {'kernel': ['linear'], 'C': [0.5, 1, 5, 10]}]\n",
    "tuned_parameters_SGD = [{'loss':['hinge','perceptron','modified_huber'],\n",
    "                         'penalty':['l2','l1'],'max_iter':[5, 10]}]\n",
    "tuned_parameters_GB = [{'loss':['deviance','exponential'],\n",
    "                        'learning_rate':[0.1, 0.2],\n",
    "                        'max_depth':[3, 5, 10]}]\n",
    "tuned_parameters_DT = [{'criterion':['gini','entropy'],\n",
    "                        'splitter':['best','random'],\n",
    "                        'max_depth':[3, 5, 10]}]\n",
    "tuned_parameters_LR = [{'penalty':['none','l2'], 'C':[0.1, 0.5, 1.0],\n",
    "                        'class_weight':[None, 'balanced'],\n",
    "                        'solver':['lbfgs']}]\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRICT\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "Support vector classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Grid scores on development set:\n",
      "0.738 (+/-0.012) for {'C': 0.5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.008) for {'C': 0.5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.757 (+/-0.000) for {'C': 0.5, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.751 (+/-0.007) for {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.769 (+/-0.013) for {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.716 (+/-0.059) for {'C': 1, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.762 (+/-0.017) for {'C': 5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.777 (+/-0.019) for {'C': 5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.719 (+/-0.055) for {'C': 5, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.765 (+/-0.018) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.777 (+/-0.018) for {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.719 (+/-0.055) for {'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.758 (+/-0.016) for {'C': 0.5, 'kernel': 'linear'}\n",
      "0.761 (+/-0.017) for {'C': 1, 'kernel': 'linear'}\n",
      "0.750 (+/-0.018) for {'C': 5, 'kernel': 'linear'}\n",
      "0.738 (+/-0.016) for {'C': 10, 'kernel': 'linear'}\n",
      "Naive Bayes classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'alpha': 1, 'fit_prior': False}\n",
      "Grid scores on development set:\n",
      "0.713 (+/-0.014) for {'alpha': 0, 'fit_prior': True}\n",
      "0.714 (+/-0.010) for {'alpha': 0, 'fit_prior': False}\n",
      "0.765 (+/-0.019) for {'alpha': 1, 'fit_prior': True}\n",
      "0.766 (+/-0.016) for {'alpha': 1, 'fit_prior': False}\n",
      "0.718 (+/-0.025) for {'alpha': 100, 'fit_prior': True}\n",
      "0.721 (+/-0.010) for {'alpha': 100, 'fit_prior': False}\n",
      "Stochastic Gradient Descent classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'loss': 'hinge', 'max_iter': 10, 'penalty': 'l2'}\n",
      "Grid scores on development set:\n",
      "0.761 (+/-0.017) for {'loss': 'hinge', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.758 (+/-0.012) for {'loss': 'hinge', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.763 (+/-0.017) for {'loss': 'hinge', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.759 (+/-0.014) for {'loss': 'hinge', 'max_iter': 10, 'penalty': 'l1'}\n",
      "0.725 (+/-0.017) for {'loss': 'perceptron', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.677 (+/-0.032) for {'loss': 'perceptron', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.724 (+/-0.009) for {'loss': 'perceptron', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.682 (+/-0.008) for {'loss': 'perceptron', 'max_iter': 10, 'penalty': 'l1'}\n",
      "0.751 (+/-0.010) for {'loss': 'modified_huber', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.741 (+/-0.013) for {'loss': 'modified_huber', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.758 (+/-0.026) for {'loss': 'modified_huber', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.730 (+/-0.016) for {'loss': 'modified_huber', 'max_iter': 10, 'penalty': 'l1'}\n",
      "Gradient Boosting classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 10}\n",
      "Grid scores on development set:\n",
      "0.705 (+/-0.019) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.716 (+/-0.015) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.730 (+/-0.015) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.705 (+/-0.019) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.720 (+/-0.021) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.730 (+/-0.011) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.724 (+/-0.018) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.727 (+/-0.025) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.733 (+/-0.020) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.724 (+/-0.022) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.728 (+/-0.023) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.729 (+/-0.019) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10}\n",
      "Decision Tree classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "Grid scores on development set:\n",
      "0.613 (+/-0.036) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.591 (+/-0.031) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.615 (+/-0.031) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.622 (+/-0.099) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.643 (+/-0.012) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.624 (+/-0.032) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'random'}\n",
      "0.614 (+/-0.025) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.607 (+/-0.015) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.615 (+/-0.032) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.614 (+/-0.046) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.627 (+/-0.029) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.635 (+/-0.020) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}\n",
      "Logisic Regression classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Grid scores on development set:\n",
      "0.715 (+/-0.011) for {'C': 0.1, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.732 (+/-0.010) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.714 (+/-0.012) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.735 (+/-0.013) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.715 (+/-0.011) for {'C': 0.5, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.756 (+/-0.008) for {'C': 0.5, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.714 (+/-0.012) for {'C': 0.5, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.756 (+/-0.008) for {'C': 0.5, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.715 (+/-0.011) for {'C': 1.0, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.762 (+/-0.012) for {'C': 1.0, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.714 (+/-0.012) for {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.762 (+/-0.016) for {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "# Tuning hyper-parameters for recall\n",
      "Support vector classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Grid scores on development set:\n",
      "0.732 (+/-0.008) for {'C': 0.5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.757 (+/-0.004) for {'C': 0.5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.501 (+/-0.001) for {'C': 0.5, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.748 (+/-0.004) for {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.769 (+/-0.012) for {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.505 (+/-0.001) for {'C': 1, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.762 (+/-0.017) for {'C': 5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.777 (+/-0.019) for {'C': 5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.506 (+/-0.000) for {'C': 5, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.765 (+/-0.019) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.777 (+/-0.018) for {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.506 (+/-0.000) for {'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.758 (+/-0.015) for {'C': 0.5, 'kernel': 'linear'}\n",
      "0.761 (+/-0.018) for {'C': 1, 'kernel': 'linear'}\n",
      "0.750 (+/-0.019) for {'C': 5, 'kernel': 'linear'}\n",
      "0.738 (+/-0.017) for {'C': 10, 'kernel': 'linear'}\n",
      "Naive Bayes classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'alpha': 1, 'fit_prior': False}\n",
      "Grid scores on development set:\n",
      "0.713 (+/-0.014) for {'alpha': 0, 'fit_prior': True}\n",
      "0.714 (+/-0.010) for {'alpha': 0, 'fit_prior': False}\n",
      "0.761 (+/-0.021) for {'alpha': 1, 'fit_prior': True}\n",
      "0.765 (+/-0.017) for {'alpha': 1, 'fit_prior': False}\n",
      "0.585 (+/-0.011) for {'alpha': 100, 'fit_prior': True}\n",
      "0.686 (+/-0.016) for {'alpha': 100, 'fit_prior': False}\n",
      "Stochastic Gradient Descent classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'loss': 'hinge', 'max_iter': 5, 'penalty': 'l2'}\n",
      "Grid scores on development set:\n",
      "0.763 (+/-0.018) for {'loss': 'hinge', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.756 (+/-0.017) for {'loss': 'hinge', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.763 (+/-0.019) for {'loss': 'hinge', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.759 (+/-0.016) for {'loss': 'hinge', 'max_iter': 10, 'penalty': 'l1'}\n",
      "0.721 (+/-0.013) for {'loss': 'perceptron', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.687 (+/-0.035) for {'loss': 'perceptron', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.722 (+/-0.017) for {'loss': 'perceptron', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.653 (+/-0.006) for {'loss': 'perceptron', 'max_iter': 10, 'penalty': 'l1'}\n",
      "0.748 (+/-0.020) for {'loss': 'modified_huber', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.732 (+/-0.005) for {'loss': 'modified_huber', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.755 (+/-0.016) for {'loss': 'modified_huber', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.733 (+/-0.015) for {'loss': 'modified_huber', 'max_iter': 10, 'penalty': 'l1'}\n",
      "Gradient Boosting classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10}\n",
      "Grid scores on development set:\n",
      "0.702 (+/-0.017) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.717 (+/-0.016) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.730 (+/-0.011) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.702 (+/-0.016) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.715 (+/-0.018) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.725 (+/-0.016) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.722 (+/-0.017) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.727 (+/-0.020) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.728 (+/-0.023) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.721 (+/-0.023) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.729 (+/-0.019) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.731 (+/-0.017) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10}\n",
      "Decision Tree classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "Grid scores on development set:\n",
      "0.584 (+/-0.014) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.560 (+/-0.064) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.597 (+/-0.021) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.577 (+/-0.015) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.633 (+/-0.005) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.608 (+/-0.024) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'random'}\n",
      "0.579 (+/-0.024) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.577 (+/-0.029) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.598 (+/-0.022) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.572 (+/-0.043) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.614 (+/-0.025) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.607 (+/-0.040) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}\n",
      "Logisic Regression classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Grid scores on development set:\n",
      "0.714 (+/-0.011) for {'C': 0.1, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.730 (+/-0.007) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.714 (+/-0.012) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.730 (+/-0.008) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.714 (+/-0.011) for {'C': 0.5, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.754 (+/-0.009) for {'C': 0.5, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.714 (+/-0.012) for {'C': 0.5, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.754 (+/-0.006) for {'C': 0.5, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.714 (+/-0.011) for {'C': 1.0, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.761 (+/-0.013) for {'C': 1.0, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.714 (+/-0.012) for {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.761 (+/-0.015) for {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "LOOSE\n",
      "# Tuning hyper-parameters for precision\n",
      "Support vector classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Grid scores on development set:\n",
      "0.724 (+/-0.010) for {'C': 0.5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.742 (+/-0.006) for {'C': 0.5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.755 (+/-0.000) for {'C': 0.5, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.735 (+/-0.006) for {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.751 (+/-0.009) for {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.666 (+/-0.052) for {'C': 1, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.742 (+/-0.006) for {'C': 5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.010) for {'C': 5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.665 (+/-0.061) for {'C': 5, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.738 (+/-0.011) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.755 (+/-0.009) for {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.665 (+/-0.061) for {'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.741 (+/-0.010) for {'C': 0.5, 'kernel': 'linear'}\n",
      "0.740 (+/-0.008) for {'C': 1, 'kernel': 'linear'}\n",
      "0.723 (+/-0.003) for {'C': 5, 'kernel': 'linear'}\n",
      "0.714 (+/-0.008) for {'C': 10, 'kernel': 'linear'}\n",
      "Naive Bayes classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'alpha': 1, 'fit_prior': False}\n",
      "Grid scores on development set:\n",
      "0.698 (+/-0.008) for {'alpha': 0, 'fit_prior': True}\n",
      "0.698 (+/-0.006) for {'alpha': 0, 'fit_prior': False}\n",
      "0.746 (+/-0.015) for {'alpha': 1, 'fit_prior': True}\n",
      "0.748 (+/-0.015) for {'alpha': 1, 'fit_prior': False}\n",
      "0.709 (+/-0.013) for {'alpha': 100, 'fit_prior': True}\n",
      "0.710 (+/-0.013) for {'alpha': 100, 'fit_prior': False}\n",
      "Stochastic Gradient Descent classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'loss': 'hinge', 'max_iter': 10, 'penalty': 'l2'}\n",
      "Grid scores on development set:\n",
      "0.740 (+/-0.017) for {'loss': 'hinge', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.738 (+/-0.005) for {'loss': 'hinge', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.740 (+/-0.007) for {'loss': 'hinge', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.740 (+/-0.008) for {'loss': 'hinge', 'max_iter': 10, 'penalty': 'l1'}\n",
      "0.696 (+/-0.011) for {'loss': 'perceptron', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.652 (+/-0.027) for {'loss': 'perceptron', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.698 (+/-0.014) for {'loss': 'perceptron', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.666 (+/-0.015) for {'loss': 'perceptron', 'max_iter': 10, 'penalty': 'l1'}\n",
      "0.732 (+/-0.008) for {'loss': 'modified_huber', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.712 (+/-0.022) for {'loss': 'modified_huber', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.732 (+/-0.009) for {'loss': 'modified_huber', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.715 (+/-0.011) for {'loss': 'modified_huber', 'max_iter': 10, 'penalty': 'l1'}\n",
      "Gradient Boosting classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10}\n",
      "Grid scores on development set:\n",
      "0.695 (+/-0.018) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.706 (+/-0.017) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.713 (+/-0.014) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.693 (+/-0.014) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.708 (+/-0.016) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.716 (+/-0.018) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.708 (+/-0.018) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.716 (+/-0.008) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.714 (+/-0.014) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.710 (+/-0.018) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.717 (+/-0.012) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.717 (+/-0.011) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10}\n",
      "Decision Tree classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}\n",
      "Grid scores on development set:\n",
      "0.601 (+/-0.030) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.589 (+/-0.017) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.611 (+/-0.027) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.614 (+/-0.029) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.626 (+/-0.012) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.614 (+/-0.021) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'random'}\n",
      "0.600 (+/-0.030) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.590 (+/-0.037) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.608 (+/-0.033) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.597 (+/-0.048) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.620 (+/-0.025) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.629 (+/-0.020) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}\n",
      "Logisic Regression classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 1.0, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Grid scores on development set:\n",
      "0.681 (+/-0.011) for {'C': 0.1, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.717 (+/-0.005) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.684 (+/-0.013) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.721 (+/-0.008) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.681 (+/-0.011) for {'C': 0.5, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.739 (+/-0.006) for {'C': 0.5, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.684 (+/-0.013) for {'C': 0.5, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.739 (+/-0.009) for {'C': 0.5, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.681 (+/-0.011) for {'C': 1.0, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.746 (+/-0.009) for {'C': 1.0, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.684 (+/-0.013) for {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.745 (+/-0.009) for {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "# Tuning hyper-parameters for recall\n",
      "Support vector classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Grid scores on development set:\n",
      "0.717 (+/-0.011) for {'C': 0.5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.740 (+/-0.003) for {'C': 0.5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.501 (+/-0.001) for {'C': 0.5, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.732 (+/-0.002) for {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.750 (+/-0.008) for {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.505 (+/-0.001) for {'C': 1, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.742 (+/-0.006) for {'C': 5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.010) for {'C': 5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.505 (+/-0.001) for {'C': 5, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.738 (+/-0.012) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.755 (+/-0.009) for {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.505 (+/-0.001) for {'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.740 (+/-0.009) for {'C': 0.5, 'kernel': 'linear'}\n",
      "0.740 (+/-0.008) for {'C': 1, 'kernel': 'linear'}\n",
      "0.722 (+/-0.003) for {'C': 5, 'kernel': 'linear'}\n",
      "0.713 (+/-0.009) for {'C': 10, 'kernel': 'linear'}\n",
      "Naive Bayes classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'alpha': 1, 'fit_prior': False}\n",
      "Grid scores on development set:\n",
      "0.698 (+/-0.008) for {'alpha': 0, 'fit_prior': True}\n",
      "0.698 (+/-0.006) for {'alpha': 0, 'fit_prior': False}\n",
      "0.744 (+/-0.016) for {'alpha': 1, 'fit_prior': True}\n",
      "0.747 (+/-0.015) for {'alpha': 1, 'fit_prior': False}\n",
      "0.620 (+/-0.019) for {'alpha': 100, 'fit_prior': True}\n",
      "0.687 (+/-0.018) for {'alpha': 100, 'fit_prior': False}\n",
      "Stochastic Gradient Descent classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'loss': 'hinge', 'max_iter': 10, 'penalty': 'l1'}\n",
      "Grid scores on development set:\n",
      "0.738 (+/-0.008) for {'loss': 'hinge', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.735 (+/-0.003) for {'loss': 'hinge', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.739 (+/-0.009) for {'loss': 'hinge', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.739 (+/-0.009) for {'loss': 'hinge', 'max_iter': 10, 'penalty': 'l1'}\n",
      "0.693 (+/-0.020) for {'loss': 'perceptron', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.648 (+/-0.017) for {'loss': 'perceptron', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.694 (+/-0.025) for {'loss': 'perceptron', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.646 (+/-0.056) for {'loss': 'perceptron', 'max_iter': 10, 'penalty': 'l1'}\n",
      "0.728 (+/-0.005) for {'loss': 'modified_huber', 'max_iter': 5, 'penalty': 'l2'}\n",
      "0.706 (+/-0.011) for {'loss': 'modified_huber', 'max_iter': 5, 'penalty': 'l1'}\n",
      "0.732 (+/-0.005) for {'loss': 'modified_huber', 'max_iter': 10, 'penalty': 'l2'}\n",
      "0.712 (+/-0.000) for {'loss': 'modified_huber', 'max_iter': 10, 'penalty': 'l1'}\n",
      "Gradient Boosting classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 5}\n",
      "Grid scores on development set:\n",
      "0.693 (+/-0.009) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.704 (+/-0.010) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.711 (+/-0.010) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.691 (+/-0.007) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.704 (+/-0.009) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.714 (+/-0.013) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 10}\n",
      "0.708 (+/-0.015) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3}\n",
      "0.717 (+/-0.016) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 5}\n",
      "0.713 (+/-0.010) for {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 10}\n",
      "0.709 (+/-0.013) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 3}\n",
      "0.718 (+/-0.013) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 5}\n",
      "0.715 (+/-0.019) for {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10}\n",
      "Decision Tree classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "Grid scores on development set:\n",
      "0.578 (+/-0.010) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.584 (+/-0.056) for {'criterion': 'gini', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.598 (+/-0.018) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.573 (+/-0.054) for {'criterion': 'gini', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.614 (+/-0.004) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.600 (+/-0.024) for {'criterion': 'gini', 'max_depth': 10, 'splitter': 'random'}\n",
      "0.577 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'best'}\n",
      "0.568 (+/-0.016) for {'criterion': 'entropy', 'max_depth': 3, 'splitter': 'random'}\n",
      "0.590 (+/-0.021) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'best'}\n",
      "0.584 (+/-0.011) for {'criterion': 'entropy', 'max_depth': 5, 'splitter': 'random'}\n",
      "0.604 (+/-0.015) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}\n",
      "0.610 (+/-0.032) for {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}\n",
      "Logisic Regression classifier: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/kata/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 1.0, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Grid scores on development set:\n",
      "0.681 (+/-0.011) for {'C': 0.1, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.715 (+/-0.003) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.683 (+/-0.013) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.716 (+/-0.007) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.681 (+/-0.011) for {'C': 0.5, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.738 (+/-0.005) for {'C': 0.5, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.683 (+/-0.013) for {'C': 0.5, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.737 (+/-0.006) for {'C': 0.5, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.681 (+/-0.011) for {'C': 1.0, 'class_weight': None, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.745 (+/-0.009) for {'C': 1.0, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.683 (+/-0.013) for {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.744 (+/-0.007) for {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(\"STRICT\")\n",
    "print()\n",
    "GSCV(X_s_trans, Y_strict, scores, tuned_parameters_SVC, tuned_parameters_NB, \n",
    "     tuned_parameters_SGD, tuned_parameters_GB, tuned_parameters_DT,\n",
    "     tuned_parameters_LR)\n",
    "print()\n",
    "print('-----------------------------------------------')\n",
    "print()\n",
    "print(\"LOOSE\")\n",
    "GSCV(X_l_trans, Y_lose, scores, tuned_parameters_SVC, tuned_parameters_NB, \n",
    "     tuned_parameters_SGD, tuned_parameters_GB, tuned_parameters_DT,\n",
    "     tuned_parameters_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dont be fooled by Leavers saying Remain have it in the bag! Please make sure you vote! Vote Remain #VoteRemain Its common sense #StrongerIn\n",
      "Nope, not changed my mind. Brexit please...\n"
     ]
    }
   ],
   "source": [
    "print(X_strict[2654])\n",
    "print(X_strict[7458])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a pipeline using the final classifer SVC\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    SVC(C=5,gamma=1,kernel='rbf'))\n",
    "\n",
    "#training using the final classifer (strict data)\n",
    "strict = pipeline.fit(X_strict, Y_strict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I didn't think about the business side - Every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I had to trigger Article 50. It would have bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Uh we want to leave the EU but we want to keep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>#DeathtotheEU oh wow I really hate the #EU Wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>#IVotedLeave and I hope you did too! #EUref le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Annotation                                            Comment\n",
       "0           0  I didn't think about the business side - Every...\n",
       "1           0  I had to trigger Article 50. It would have bee...\n",
       "2           0  Uh we want to leave the EU but we want to keep...\n",
       "3           1  #DeathtotheEU oh wow I really hate the #EU Wha...\n",
       "4           1  #IVotedLeave and I hope you did too! #EUref le..."
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the test set\n",
    "df_ts = pd.read_csv('a2a_test_final.tsv', sep = '\\t', header=None, names=['Annotation', 'Comment'])\n",
    "df_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert test data to other forms for later using\n",
    "Xt_f = df_ts['Comment'].astype(str).values.tolist()\n",
    "Yt_f = np.array(df_ts['Annotation'].astype(str).values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strict_accuracy: 0.8275862068965517\n"
     ]
    }
   ],
   "source": [
    "#prediction using the test set\n",
    "pred_strict = strict.predict(Xt_f)\n",
    "strict_accuracy = accuracy_score(Yt_f, pred_strict)\n",
    "print('strict_accuracy: ' + str(strict_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[450, 106],\n",
       "       [ 94, 510]])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for prediction\n",
    "\n",
    "confusion_matrix(pred_strict, Yt_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC precision: 0.8275639801375095\n",
      "SVC recall: 0.8268616894563818\n",
      "SVC fscore: 0.827123695976155\n"
     ]
    }
   ],
   "source": [
    "# calculate precision_recall_fscore\n",
    "print('SVC precision: ' + str(precision_recall_fscore_support(pred_strict, Yt_f, average='macro')[0]))\n",
    "print('SVC recall: ' + str(precision_recall_fscore_support(pred_strict, Yt_f, average='macro')[1]))\n",
    "print('SVC fscore: ' + str(precision_recall_fscore_support(pred_strict, Yt_f, average='macro')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Being', 'a', 'member', 'of', 'the', 'European', 'Union', 'is', 'a', 'bit', 'like', 'going', 'to', 'a', 'sandwich', 'shop', 'and', 'buying', 'a', '£3', 'sandwich', 'with', 'a', '£5', 'note', 'and', 'getting', 'back', 'over', '£1,000', 'in', 'change'], ['Brexit', 'is', 'bad.', 'Immigrants', 'make', 'Britain', 'great.', 'They', 'also', 'cooked', 'your', 'food', 'The', 'London', 'restaurant', 'causing', 'a', 'stir', 'with', 'anti-#Brexit', 'messages', 'on', 'your', 'bill'], ['Britain', 'is', 'basically', 'Pompeii', 'if', 'the', 'Pompeii', 'had', 'voted', 'for', 'the', 'volcano', '...', \"I'm\", 'DEAD!', ':p'], [\"Britain's\", 'exit', 'is', 'a', 'huge', 'blow', 'to', 'the', 'dream', 'of', 'a', 'united', 'Europe', 'No.', 'It', 'is', 'the', 'end', 'of', 'an', 'anti-national,', 'centralized,', 'globalist,', 'neoliberal', 'and', 'authoritarian', 'system', 'and', 'organism', 'like', 'the', 'EU', 'and', 'its', 'hegemonic', 'power', 'over', 'Europe.']]\n"
     ]
    }
   ],
   "source": [
    "#splitting words in comments using (X_lose)\n",
    "words = []\n",
    "for line in X_lose:\n",
    "    word = line.strip().split()\n",
    "    words.append(word)\n",
    "print(words[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Figure 1: ROC curve for SVC classifier')"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve\n",
    "plt.style.use('bmh')\n",
    "\n",
    "scores = loose.decision_function(Xt_f)\n",
    "fprs, tprs, _ = roc_curve(Yt_f, scores, pos_label='1')\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(fprs, tprs)\n",
    "\n",
    "plt.plot([0, 1], 'k:')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "\n",
    "roc_auc_score(Yt_f =='1', scores)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('Figure 1: ROC curve for SVC classifier', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0940126050420168"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fprs, tprs, _ = roc_curve(Yt_f, scores, pos_label='0')\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(fprs, tprs)\n",
    "\n",
    "plt.plot([0, 1], 'k:')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "\n",
    "roc_auc_score(Yt_f=='0', scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
